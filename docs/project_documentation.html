<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MCP on Amazon Bedrock - Implementation Documentation</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        h1, h2, h3, h4 {
            color: #0066cc;
            margin-top: 30px;
        }
        h1 {
            border-bottom: 2px solid #0066cc;
            padding-bottom: 10px;
        }
        pre, code {
            background-color: #f5f5f5;
            border-radius: 5px;
            padding: 10px;
            overflow-x: auto;
            font-family: 'Courier New', Courier, monospace;
        }
        .diagram {
            background-color: #f9f9f9;
            padding: 15px;
            border-radius: 5px;
            border: 1px solid #ddd;
            margin: 20px 0;
        }
        .note {
            background-color: #fffacd;
            padding: 15px;
            border-left: 4px solid #ffcc00;
            margin: 20px 0;
        }
        .implementation {
            background-color: #f0f8ff;
            padding: 15px;
            border-left: 4px solid #0066cc;
            margin: 20px 0;
        }
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
    </style>
</head>
<body>
    <h1>MCP on Amazon Bedrock - Implementation Documentation</h1>
    
    <section>
        <h2>Introduction</h2>
        <p>
            This documentation provides detailed information about the implementation of the ReAct (Reasoning and Acting) design pattern in the MCP (Model Conversation Protocol) on Amazon Bedrock project. The project enables AI agents powered by Amazon Bedrock models to interact with external tools through a standardized protocol, creating powerful agents that can perform complex tasks.
        </p>
    </section>

    <section>
        <h2>ReAct Design Pattern Overview</h2>
        <p>
            ReAct is an AI agent design pattern that combines reasoning and acting in a loop where the agent:
        </p>
        <ol>
            <li><strong>Observes</strong> the current state or user request</li>
            <li><strong>Reasons</strong> about what actions to take</li>
            <li><strong>Acts</strong> by calling appropriate tools</li>
            <li><strong>Observes</strong> the results of those actions</li>
            <li><strong>Repeats</strong> this cycle until the task is complete</li>
        </ol>
        
        <div class="diagram">
            <pre>
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│             │     │             │     │             │
│   Observe   │────▶│   Reason    │────▶│    Act      │
│             │     │             │     │             │
└─────────────┘     └─────────────┘     └─────────────┘
       ▲                                      │
       │                                      │
       └──────────────────────────────────────┘
                    Observe Results
            </pre>
        </div>
    </section>

    <section>
        <h2>Implementation Architecture</h2>
        
        <h3>Core Components</h3>
        <ul>
            <li><strong>FastAPI Server (main.py)</strong> - Main server that handles API endpoints and user sessions</li>
            <li><strong>MCP Client (mcp_client.py)</strong> - Client for connecting to and managing tool servers</li>
            <li><strong>Chat Client (chat_client.py)</strong> - Basic client for interacting with Bedrock models</li>
            <li><strong>Chat Client Stream (chat_client_stream.py)</strong> - Extended client with streaming support and ReAct implementation</li>
        </ul>
        
        <h3>ReAct Flow Architecture</h3>
        <div class="diagram">
            <pre>
┌─────────────┐    ┌─────────────────┐    ┌───────────────┐
│  User Query  │───▶│  Bedrock Model  │───▶│  Think/Reason │
└─────────────┘    └─────────────────┘    └───────┬───────┘
                                                  │
                           ┌─────────────────────▶▼
                           │                 ┌────────────┐
                           │                 │  Generate  │
                           │                 │ Tool Call  │
                           │                 └──────┬─────┘
                           │                        │
┌─────────────┐    ┌───────┴───────┐        ┌──────▼─────┐
│    Final    │◀───┤ Continue with │◀───────┤ Execute    │
│   Response  │    │  Reasoning    │        │   Tool     │
└─────────────┘    └───────────────┘        └────────────┘
            </pre>
        </div>
    </section>

    <section>
        <h2>Key ReAct Implementation Features</h2>
        
        <h3>1. Tool Registration and Namespacing</h3>
        <div class="implementation">
            <p>
                The MCPClient class handles tool registration and provides namespacing to distinguish between tools from different servers using a delimiter-based approach.
            </p>
            <pre>
# From mcp_client.py
@staticmethod
def get_tool_name4llm(server_id, tool_name, norm=True, ns_delimiter=delimiter):
    """Convert MCP server tool name to llm tool call"""
    # prepend server prefix namespace to support multi-mcp-server
    tool_key = server_id + ns_delimiter + tool_name
    tool_name4llm = tool_key if not norm else MCPClient.normalize_tool_name(tool_key)
    tool_name_mapping[tool_key] = tool_name4llm
    tool_name_mapping_r[tool_name4llm] = tool_key
    return tool_name4llm</pre>
        </div>

        <h3>2. Reasoning Process</h3>
        <div class="implementation">
            <p>
                When Claude 3.7 Sonnet is used, there's explicit support for the "reasoning" phase of ReAct, captured in the handling of <code>reasoningContent</code>.
            </p>
            <pre>
# From chat_client_stream.py
if "reasoningContent" in delta.get("delta", {}):
    if 'signature' in delta["delta"]['reasoningContent']:
        thinking_signature = delta["delta"]['reasoningContent']['signature']
    if 'text' in delta["delta"]['reasoningContent']:
        thinking_text += delta["delta"]['reasoningContent']["text"]</pre>
        </div>

        <h3>3. Multi-turn Tool Execution Loop</h3>
        <div class="implementation">
            <p>
                The main ReAct loop implementation shows how the agent observes results and continues reasoning:
            </p>
            <pre>
# From chat_client_stream.py
while turn_i <= max_turns and stop_reason != 'end_turn':
    # Process LLM response
    # ... 
    
    # Handle tool use in content block
    if event["type"] == "block_start":
        block_start = event["data"]
        if "toolUse" in block_start.get("start", {}):
            current_tool_use = block_start["start"]["toolUse"]
            tool_calls.append(current_tool_use)
    
    # Handle message stop and tool use
    if event["type"] == "message_stop":     
        stop_reason = event["data"]["stopReason"]
        
        # Handle tool use if needed
        if stop_reason == "tool_use" and tool_calls:
            # Execute tools, process results, feed back to LLM
            # ...
            
            # Append results to message history for context
            messages.append(tool_result_message)
            
            # Continue the conversation with the LLM
            # ...</pre>
        </div>

        <h3>4. Parallel Tool Execution</h3>
        <div class="implementation">
            <p>
                The system executes multiple tool calls in parallel for efficiency:
            </p>
            <pre>
# Using asyncio.gather for parallel tool execution
call_results = await asyncio.gather(*[execute_tool_call(tool) for tool in tool_calls])</pre>
        </div>

        <h3>5. Error Handling</h3>
        <div class="implementation">
            <p>
                The system handles tool execution errors and reports them back to the LLM:
            </p>
            <pre>
# Error handling in tool execution
except Exception as err:
    err_msg = f"{tool['name']} tool call is failed. error:{err}"
    return [{
        "toolUseId": tool['toolUseId'],
        "content": [{"text": err_msg}],
        "status": 'error'
    }]*3</pre>
        </div>

        <h3>6. Exponential Backoff and Retries</h3>
        <div class="implementation">
            <p>
                The system implements retry logic with exponential backoff for handling rate limits:
            </p>
            <pre>
def exponential_backoff(self, attempt):
    """Calculate exponential backoff delay with jitter"""
    delay = min(self.max_delay, self.base_delay * (2 ** attempt))
    jitter = random.uniform(0, 0.1 * delay)  # 10% jitter
    return delay + jitter</pre>
        </div>
    </section>

    <section>
        <h2>User Session Management</h2>
        <p>
            The system maintains user-specific sessions with their own tool configurations and conversation history:
        </p>
        <div class="implementation">
            <pre>
class UserSession:
    def __init__(self, user_id):
        self.user_id = user_id
        self.chat_client = ChatClientStream()
        self.mcp_clients = {}  # User-specific MCP clients
        self.last_active = datetime.now()
        self.session_id = str(uuid.uuid4())
        self.lock = asyncio.Lock()  # For synchronizing session operations</pre>
        </div>
        
        <p>
            This design allows for personalized agent experiences with user-specific tool configurations.
        </p>
    </section>

    <section>
        <h2>Tool Configuration and Management</h2>
        <p>
            The system supports both global and user-specific tool configurations:
        </p>
        
        <h3>Tool Configuration Data Flow</h3>
        <div class="diagram">
            <pre>
┌────────────────┐     ┌─────────────────┐      ┌────────────────┐
│ Global Server  │────▶│   User Session   │─────▶│   MCP Client   │
│ Configurations │     │ Configurations   │      │   Instances    │
└────────────────┘     └─────────────────┘      └───────┬────────┘
                                                        │
                                                        ▼
┌────────────────┐     ┌─────────────────┐      ┌────────────────┐
│  LLM Model     │◀────┤ Tool Configs    │◀─────┤ Tool Schemas   │
│  with Tools    │     │ for LLM         │      │ from Servers   │
└────────────────┘     └─────────────────┘      └────────────────┘</pre>
        </div>
        
        <h3>Adding and Removing Tool Servers</h3>
        <div class="implementation">
            <p>The system provides API endpoints for dynamically adding and removing tool servers:</p>
            <pre>
@app.post("/v1/add/mcp_server")
async def add_mcp_server(...)
    # Connect to MCP server dynamically
    # Store configuration for persistence
    
@app.delete("/v1/remove/mcp_server/{server_id}")
async def remove_mcp_server(...)
    # Clean up resources
    # Remove configuration</pre>
        </div>
    </section>

    <section>
        <h2>ReAct Interaction Flow Details</h2>
        
        <h3>Detailed Step-by-Step Flow</h3>
        <ol>
            <li><strong>User Query:</strong> The user submits a question or request</li>
            <li><strong>Query Processing:</strong> The request is routed to the user's session</li>
            <li><strong>Tool Configuration:</strong> Available tools are gathered from connected servers</li>
            <li><strong>Initial LLM Call:</strong> The query is sent to the LLM with tool configurations</li>
            <li><strong>Reasoning:</strong> The LLM reasons about the query (explicit in Claude 3.7)</li>
            <li><strong>Tool Selection:</strong> If needed, the LLM requests a tool</li>
            <li><strong>Tool Parsing:</strong> The system parses the tool name to identify the server</li>
            <li><strong>Tool Execution:</strong> The tool is executed on the appropriate server</li>
            <li><strong>Result Processing:</strong> Tool results are formatted for the LLM</li>
            <li><strong>Continued Reasoning:</strong> The LLM continues reasoning with new information</li>
            <li><strong>Final Response:</strong> The LLM provides the final answer</li>
        </ol>
        
        <h3>Message Structure</h3>
        <div class="implementation">
            <p>
                The message structure maintains the conversation history and tool results:
            </p>
            <pre>
# Assistant message with reasoning and tool use
assistant_message = {
    "role": "assistant",
    "content": thinking_block + tool_use_block + text_block if thinking_signature else text_block + tool_use_block
}     

# Tool result message
tool_result_message = {
    "role": "user",
    "content": tool_results_content
}</pre>
        </div>
    </section>

    <section>
        <h2>Advanced ReAct Features</h2>
        
        <h3>1. Explicit Reasoning with Claude 3.7 Sonnet</h3>
        <p>
            The system supports explicit "thinking" steps with Claude 3.7 Sonnet, capturing the model's reasoning process:
        </p>
        <div class="implementation">
            <pre>
# Enable thinking/reasoning with Claude 3.7
if enable_thinking:
    additionalModelRequestFields = {"reasoning_config": { "type": "enabled","budget_tokens": extra_params.get("budget_tokens",1024)}}
    inferenceConfig={"maxTokens":max(extra_params.get("budget_tokens",1024) + 1, max_tokens),"temperature":1,}</pre>
        </div>
        
        <h3>2. Image Support</h3>
        <p>
            The system can handle image outputs from tools, expanding the range of possible tools:
        </p>
        <div class="implementation">
            <pre>
# Processing image content from tools
image_content = [{"image":{"format":x.mimeType.replace('image/',''), "source":{"bytes":base64.b64decode(x.data)} } } for x in result.content if x.type == 'image']</pre>
        </div>
        
        <h3>3. Memory Management for Images</h3>
        <p>
            The system includes memory management for images to prevent context window overflow:
        </p>
        <div class="implementation">
            <pre>
# Manage image history to prevent context window overflow
if only_n_most_recent_images:
    maybe_filter_to_n_most_recent_images(
        messages,
        only_n_most_recent_images,
        min_removal_threshold=image_truncation_threshold,
)</pre>
        </div>
    </section>

    <section>
        <h2>Conclusion</h2>
        <p>
            The implementation of the ReAct pattern in this project provides a sophisticated framework for AI agents that can:
        </p>
        <ul>
            <li>Reason about problems and decide what tools to use</li>
            <li>Execute tools from multiple sources with proper namespacing</li>
            <li>Process tool results and incorporate them into further reasoning</li>
            <li>Maintain context across multiple turns of tool use</li>
            <li>Handle errors gracefully and retry operations when appropriate</li>
            <li>Support streaming responses for real-time interaction</li>
            <li>Manage user-specific tool configurations and sessions</li>
        </ul>
        
        <p>
            This implementation enables the creation of powerful AI agents that can solve complex problems by combining the reasoning capabilities of LLMs with the practical capabilities of external tools.
        </p>
    </section>

</body>
</html>